# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1joJPqvY99P-cejVIfmdjOeUd7aDUmZk4
"""

import tweepy           # Para consumir la API de Tweeter
import pandas as pd     # Para análisis de datos
import numpy as np      # Para cálculo numérico
import pandas_explode
pandas_explode.patch()
import re
from datetime import datetime, timedelta
from pandas import DataFrame

consumer_key = "wgCCW5aTILpcbbBIYnqCQI9xQ"
consumer_secret = "9vj4Nn9H3RAEae23OBkIxTFzzg5rZip4VsY4QnaRZqGoJ0Qoik"
access_key = "1020677630-sHihxB5vLWEw87v2c6nyDhzwg4HdAlZCfDVwrpI"
access_secret = "Q9LYhm2i7EuHW66ohVwY3uRPCGAMpBn7v3CVWfMvnJh7v"
# Creamos el handler App
auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)
# Guardamos en una variable
api = tweepy.API(auth)

class twitterscrapper():
    def __init__(self):
        self.simple_list = []

    def scrape(self):
        for status in tweepy.Cursor(api.user_timeline, screen_name="IGecuador", exclude_replies=True, include_rts=False,
                                    tweet_mode="extended").items():
            print(status)
            self.simple_list.append([status.full_text, status.created_at, status.favorite_count, status.retweet_count,
                                [h["text"] for h in status.entities["hashtags"]]])

        self.simple_list = pd.DataFrame(self.simple_list, columns=["Text", "Created at", "Likes", "Retweets", "Hashtags"])
        return self.formato(self.simple_list);

    def limpiar_tokenizar(self, texto):
        nuevo_texto = re.sub('http\S+', ' ', texto)
        nuevo_texto = re.sub("\\s+", ' ', nuevo_texto)
        nuevo_texto = nuevo_texto.split(sep = ' ')
        return(nuevo_texto)

    def formato(self, df):
        sismos_id = df
        sismos_id['texto_tokenizado'] = sismos_id['Text'].apply(lambda x: self.limpiar_tokenizar(x))
        sismos_id = sismos_id.explode('texto_tokenizado', axis=1)
        sismos_id['Hashtags'] = sismos_id['Hashtags'].astype(str)
        sismos_id = sismos_id[sismos_id["Hashtags"] == "['SISMO']"]
        cadenas = 'Revisado|Preliminar'
        sismos_id = sismos_id[sismos_id['Text'].str.contains(cadenas, regex=True)]
        sismos_id = sismos_id.reset_index()
        sismos_id = sismos_id.drop(["index"], axis=1)
        sismos_id = sismos_id.iloc[:, [7,8,9,10,12,14,19,20,21,22] ]
        sismos_id.columns = ['ID','tipo', "fecha", "hora", "maginitud", "Prof", "lugar", "lugar1", "latitud", "longitud"]
        sismos_id["fechahora"] = sismos_id["fecha"] + " " + sismos_id["hora"]
        sismos_id['fechahora'] = pd.to_datetime(sismos_id['fechahora'])
        sismos_pre  = sismos_id[sismos_id["tipo"] == "Preliminar"]
        sismos_pre = sismos_pre.reset_index()
        sismos_pre = sismos_pre.drop(["index"], axis=1)
        sismos_rev  = sismos_id[sismos_id["tipo"] == "Revisado"]
        sismos_rev = sismos_rev.reset_index()
        sismos_rev = sismos_rev.drop(["index"], axis=1)
        sismos_pre["Mag"] = sismos_pre["maginitud"].replace({'Magnitud:':''}, regex=True)
        sismos_pre["lugar"] = sismos_pre["lugar"].replace({'Latitud:':''}, regex=True)
        sismos_pre["lugar1"] = sismos_pre["lugar1"].replace({'Latitud:':''}, regex=True)
        sismos_pre["lugarcompleto"] = sismos_pre["lugar"] + " " + sismos_pre["lugar1"]
        sismos_pre['lugarcompleto'] = sismos_pre['lugarcompleto'].str.replace('\d+', '')
        lugares = sismos_pre["lugarcompleto"].str.split(',', expand=True)
        lugares = lugares.iloc[:, [0,1] ]
        lugares.columns = ['Ciudad', 'Region']
        sismos_pre = pd.concat([sismos_pre, lugares], axis=1)
        sismos_pre["latitud2"] = sismos_pre["latitud"]
        sismos_pre['lugar1'] = sismos_pre['lugar1'].apply(lambda x: re.sub(r'[A-Za-z,:]','',x))
        sismos_pre["lugar1"] = sismos_pre["lugar1"].fillna(0)
        sismos_pre['lugar1'] = pd.to_numeric(sismos_pre['lugar1'].str.replace(",", ""), errors='coerce')
        sismos_pre["lugar1"] = sismos_pre["lugar1"].fillna(0)
        sismos_pre['latitud'] = sismos_pre['latitud'].apply(lambda x: re.sub(r'[A-Za-z,:]','',x))
        sismos_pre['latitud'] = pd.to_numeric(sismos_pre['latitud'].str.replace(",", ""), errors='coerce')
        sismos_pre.loc[sismos_pre.latitud <=-50,'latitud']= 0
        sismos_pre['Lat'] = sismos_pre['lugar1'] +  sismos_pre['latitud']
        sismos_pre['longitud'] = sismos_pre['longitud'].apply(lambda x: re.sub(r'[A-Za-z,:]','',x))
        sismos_pre["longitud"] = sismos_pre["longitud"].fillna(0)
        sismos_pre['longitud'] = pd.to_numeric(sismos_pre['longitud'].str.replace(",", ""), errors='coerce')
        sismos_pre["longitud"] = sismos_pre["longitud"].fillna(0)
        sismos_pre['latitud2'] = sismos_pre['latitud2'].apply(lambda x: re.sub(r'[A-Za-z,:]','',x))
        sismos_pre['latitud2'] = pd.to_numeric(sismos_pre['latitud2'].str.replace(",", ""), errors='coerce')
        sismos_pre.loc[sismos_pre.latitud2 >=-50,'latitud2']= 0
        sismos_pre['Long'] = sismos_pre['longitud'] +  sismos_pre['latitud2']
        sismos_pre = sismos_pre.iloc[:, [0,11, 16, 17, 5, 14, 10]]
        sismos_pre = sismos_pre.rename(columns={'fechahora':'Hora UTC'})
        sismos_rev = sismos_rev.iloc[:, [0,10]]
        sismos_rev = sismos_rev.rename(columns={'fechahora':'Update'})
        df_new = pd.merge(left=sismos_pre, right=sismos_rev, on='ID')
        return (df_new)